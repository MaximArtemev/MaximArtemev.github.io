# Site
repository: sproogen/resume-theme
favicon: images/favicon.ico

# Content configuration version
version: 2

# Personal info
name: Maxim Artemev
title: Deep Learning Wizzard
email: mrartemev.me@gmail.com
website: shorturl.at/kX567
website_title: CV
phone: meretemev
phone_title: telegram

darkmode: never
#github_username:  MaximArtemev
linkedin_username: maxim-artemev

# About Section
about_title: About Me
about_profile_image: images/profile1.png
about_content: | # this will include new lines to allow paragraphs
  Hello there! My name is Max (short for Maksim) and I am a seasoned deep learning engineer with a passion for image-to-image GANs, Normalizing Flows, and Visual Transformers.
  I am currently a member of the talented team at [Zero10](https://zero10.app/), a seed-stage startup, where I am working on improving our state-of-the-art multitask model for person segmentation and pose estimation.
  Together we are creating real-time fashion try-on algorithms that run at 30 FPS on mobile and produce state-of-the-art results.

  I began my career at [Lambda](https://cs.hse.ru/en/lambda/) laboratory, where I focused on generative models and their application to high-energy physics.
  Specifically, I collaborated with the [Large Hadron Collider beauty experiment](https://home.cern/science/experiments/lhcb) on fast particle simulation using GANs
  I then worked as a CV engineer at [PicsArt](https://picsart.com/en), where I developed image-to-image hair recoloring GANs and publishing papers on Normalizing Flows and GANs.
  Before joining Zero10, I was at ByteDance Singapore, where I developed video-level embeddings for video comparison and made many other improvements to deduplication filters.

  If interested, you can find my resume [here](shorturl.at/kX567).

  If you wish to contact me directly, please feel free to use my personal email: *mrartemev.me@gmail.com* or my telegram: *@ meretemev*


content:
  - title: TikTok - ByteDance
    layout: list
    caption: October 2021 - Present
    link: https://www.bytedance.com/en/
    sub_title: Computer Vision Engineer
    content:
      - title: TikTok Deduplication (Singapore)
        layout: left
        border: weak
        description: | 
          As a part of the deduplication team located in Singapore, my goal was to improve the quality of the TikTok duplicates recognition algorithm.
          At the time, I was working jointly with engineering and research teams thus creating both practical and new ways to create a de-duplication pipelines.
          Using image features from an external CNN model and a number of various text features (fasttext, word2vec, etc)
            I have implemented multiple robust frame feature based filters reducing total number of duplicates that end user sees by 5\%.
          Additionally, I was setting up monitoring, building processing services jointly with other engineers, and writing python code to wrap existing OCR models, usual stuff.

          My big project there was designing a new architecture for video-level embeddings that could be useful for video deduplication.
          Using [Visual Transformers](https://arxiv.org/abs/2010.11929) and [Masked AutoEncoder approach](https://arxiv.org/abs/2111.06377)
            I have created a robust, scale-invariant ViT model that can produce embeddings that could be used in different services, not only deduplication.

  - title: Projects @ PicsArt
    layout: list
    caption: May 2020 - October 2021
    link: https://picsart.com/ru
    sub_title: Computer Vision Researcher
    content:
      - title: Hair Recoloring
        layout: left
        border: weak
        description: |
          When I joined Picsart, I was the only one working on a hair recoloring tool.
          After year and a half, I was leading a small team working on multiple beautification solutions for the app.

          So, my initial goal was to deliver a simple backend application for photo-realistic hair recoloring.
          In the end, me and the team I was leading was able to produce a very fast *(10 FPS)* and lightweight *(less than 4Mb)* model suitable for use in mobile environments.

          This journey consisted of a number of steps:

          * Data collection and annotation, data filtration, bias (gender, race, hair color, hair type) elimination.
          * Initial model research and training: The initial solution was relatively big and heavy; [UNet](https://arxiv.org/abs/1505.04597)-like generator model in a [StarGAN](https://arxiv.org/abs/1912.01865)-like framework.
          * Distillation: I had a team of researchers at this point. We tried multiple approaches to GAN distillation ([1](https://ojs.aaai.org/index.php/AAAI/article/view/5765), [2](https://arxiv.org/pdf/1902.00159.pdf), [3](https://arxiv.org/abs/2103.03467), [4](https://www.semanticscholar.org/paper/KDGAN%3A-Knowledge-Distillation-with-Generative-Wang-Zhang/2a4f50cca273813da26ef25e5bda7d01b5e0dde6)) and decided to develop our own, paper on that in submission to ECCV 2022.
          * Quantization: we used a simple static quantization from [Pytorch beta](https://pytorch.org/docs/stable/quantization.html)
          * For mobile inference, I packed everything in <mark>ONNX</mark> and <mark>MNN</mark> frameworks.

          #### Examples:
          ![](images/haircolor/image1.jpg)

          ![](images/haircolor/image2.jpg)
          
          ![](images/haircolor/271.jpg)

          We are continuing to increase the quality and latency of the model to this day. For instance, the precise calculation of the hair mask was taken too much time, so we created a novel approach for our model to generate without it. This way, we saved approximately *0.2 ms* from inference time, making it possible to use hair recoloring on video sequences.
        
      - title: Hair Transfer
        layout: left
        border: weak
        description: |
          Another project for our beautification team. I mainly supervised it, but I think I should still state it here. 
          
          The goal was to create an algorithm that could photo-realistically insert the hair from the reference image to the source image. The most exciting steps in the project pipeline are:
          * Facial keypoint detection and face alignment
          * Facial segmentation and hair alpha mask calculation
          * Statistical recoloring, alpha-blending
          * Inpainting
      - title: Video Enhancement
        layout: left
        border: weak
        description: |
          PicsArt aims to shift to be a video platform, so there were a lot of video-related projects. I worked on the Video Auto Adjustment or Video Enhancement task. We wanted to have a tiny but capable model to auto-adjust brightness, contrast, sharpness, and other adjustment handles on any given video to make it "better." The main aim of this project is to give the user control over adjust parameters like in photo editing.

          The solution is simple: a small fully-convolutional model that performs a regression over the adjust parameters based on LAB video frames. But unfortunately, this solution is only available for fully annotated datasets. For this reason, the logical extension of the project is to build a model that could learn auto adjustment in an unsupervised fashion.
          
          #### Examples (clickable):

          [![Here should be a video link](images/preview_1.png)](https://drive.google.com/file/d/1wNRTdq3FlVdrcy9_UaYAqaJdjcS0Zcj2/view?usp=sharing)

          [![Here should be a video link](images/preview_2.png)](https://drive.google.com/file/d/10YETE0DiamgfpYHcsfetI6JbxNBMz0Z1/view?usp=sharing)

  - title: Projects @ CERN
    layout: list
    caption: August 2019 - August 2020
    link: https://cs.hse.ru/en/lambda/
    sub_title: Deep Learning Researcher
    content:
      - title: Ring Imaging Cherenkov detector
        layout: left
        border: weak
        description: | # this will include new lines to allow paragraphs
          [Ring Imaging Cherenkov (RICH) detector](https://lhcb-public.web.cern.ch/en/detector/RICH-en.html) is one of the steps for the Large Hadron Collider beauty experiment. Basically, we want to pass a particle through it and calculate the probability of a particle being a particular type. While the classification model is straightforward, it requires a lot of data to train it. 
          
          To solve this, our team produced a good conditional [Cramer GAN](https://arxiv.org/abs/1705.10743) to generate a lot of data to simulate specific LHCb experiments. This allowed for a fast data simulation (around 10000 events per second), especially compared with Monte-Carlo methods (2-5 events per second), previously used by physicists.

      - title: Deep Underground Neutrino Experiment (Geneva)
        layout: left
        border: weak
        description: |
          This project is a collaboration with [FermiLab](https://www.fnal.gov/). It aimed to study neutrino interactions with matter. My goal was to build a stable pre-processing pipeline for sparse data and build low-latency models for online event filtering. There is a good [presentation](https://indico.cern.ch/event/773049/contributions/3474765/attachments/1937737/3211868/GraphNNDune.pdf) at [CHEP 2019](https://indico.cern.ch/event/773049/contributions/3474765/) that nicely summarizes the whole project. 

          My contribution to this project is a graph neural network that denoise and sparsifies events as a part of the engineering pipeline. As far as I know, the proposed solution is still used inside current DUNE experiments.

  - title: Additional Experience
    layout: list 
    content:
      - layout: left
        title: Higher School of Economics
        link: https://www.hse.ru/en/edu/courses/339563270
        sub_title: Teacher
        caption: September 2018 - Present
        description: | 
            I started teaching during my second year at the university. At first, it was just private counseling sessions. Then I became a teacher's assistant on various deep learning-related courses.
            
            A couple of years ago, I taught a [half a year-long course on intro to machine and deep learning](https://www.hse.ru/en/news/admission/207148580.html) for students in the "International Relations" faculty. 
            
            After my graduation, together with my supervisor in Lambda laboratory, I started my own course called *Generative Models*. This semester-long course covers most of the state-of-the-art generative models, including GANs, VAEs, Normalizing Flows, etc. 

      - layout: left
        title: Yandex
        link: https://en.wikipedia.org/wiki/Yandex_Zen
        sub_title: Intern
        description: | 
            During my student years, I got an internship at Yandex. I worked on various NLP models specifically tailored to solve deduplication tasks for three months. While most of my work there was about the text embeddings like word2vec, fasttext, doc2vec, I managed to ship a [Siamese neural network](https://en.wikipedia.org/wiki/Siamese_neural_network) to the production, increasing deduplication quality.

  - title: Education
    layout: list
    content:
      - layout: left
        title: Higher School of Economics (Moscow)
        caption: 2015-2019
        sub_title: BSc Computer Science
        quote: >
          Even though it is called a "Higher School of Economics", the faculty I studied in was considered top-1 computer science in Russia and was specifically tailored to teach applied machine learning skills.

        description: |
          During my time at HSE, I learned most of my key skills that have I have taken through my career, such as teamwork and working to tight deadlines. I thoroughly enjoyed my time at university and learned a lot about a healthy work-life balance.

          I consistently went for top places in the intra-university <mark>Kaggle</mark> competitions and worked as a teacher assistant during my last two years there.

          My bachelor thesis is about GANs for the [fast simulation of particle interactions](https://arxiv.org/abs/1905.11825) for CERN's LHCb experiment.  


  - title: Papers 
    layout: list
    content:
      - layout: left
        description: |
          My work with Lambda laboratories was very productive in terms of papers and talks:

          * Paper at the Advanced Computing and Analysis Techniques in Physics Research 2019: [Fast Data-Driven simulation of Cherenkov Detectors Using Generative Adversarial Networks](https://arxiv.org/abs/1905.11825)
          * Poster at NeurIPS 2019 about the same thing

          During my time there, I made several publically available talks and lectures about generative models in high energy physics:

          * 24th International Conference on Computing in High-Energy and Nuclear Physics, 2019
          * Innovative Team-Teaching For Physics, 2019
          * Machine Learning in High Energy Physics Summer School, Oxford, 2019

          For now, I'm yet to publish a paper in collaboration with PicsArt, but we have three new submissions to ECCV 2022:

          * Knowledge Distillation of Normalizing Flows

          Here we explore conventional knowledge distillation methods applied to Normalizing Flows. We propose a novel NF-specific KD solution that improves student flow quality by more than 30% compared to conventional methods.

          * Deep Normalizing Flows

          The name says it all! Basically, we test how deep we can go with Normalizing Flows and increasing metrics effectively

          * Very Tiny StarGan v2

          During our hair recoloring project, we created an exciting method to distill an image-to-image GAN. It allows for a stable and fast distillation procedure of current state-of-the-art image translation GAN, StarGAN v2.

# Footer
footer_show_references: true
# references_title: References on request (Override references text)

# Build settings
remote_theme: sproogen/resume-theme

sass:
  sass_dir: _sass
  style: compressed

plugins:
 - jekyll-seo-tag

# Site
repository: sproogen/resume-theme
favicon: images/favicon.ico

# Content configuration version
version: 2

# Personal info
name: Maxim Artemev
title: Deep Learning Wizzard
email: mrartemev.me@gmail.com
website: shorturl.at/kX567
website_title: CV
phone: meretemev
phone_title: telegram

darkmode: never
linkedin_username: maxim-artemev

# About Section
about_title: About Me
about_profile_image: images/profile1.png
about_content: | # this will include new lines to allow paragraphs
  Hello there! My name is Max (short for Maksim) and I am an experienced deep learning engineer with a passion
  for image-to-image GANs, Normalizing Flows, and Visual Transformers.

  I am currently a member of the talented engineering team at [Zero10](https://zero10.app/),
  a seed-stage startup focused on creating a **virtual fashion** try-on futuristic platform.
  I am working on improving our state-of-the-art multitask model for **person segmentation** and **pose estimation**.
  Together we are creating real-time fashion try-on algorithms
  that run at **30 FPS** on mobile and produce state-of-the-art results.

  I began my career at [Lambda](https://cs.hse.ru/en/lambda/) laboratory,
  where I focused on **generative models** and their application to high-energy physics.
  Specifically, I was in a collaboration with the [Large Hadron Collider beauty experiment](https://home.cern/science/experiments/lhcb)
  on fast particle simulation using **GANs**.
  I then worked as a CV engineer at [PicsArt](https://picsart.com/en),
  where I worked on **image-to-image** hair recoloring GANs and published papers on **Normalizing Flows** and **GANs**.
  Before joining Zero10, I was at [ByteDance Singapore](https://www.bytedance.com/en/),
  where I developed **video-level embeddings** for video comparison and made improvements to deduplication filters.

  If interested, you can find my resume [here](shorturl.at/kX567).

  If you wish to contact me directly, please feel free to use:
  * My personal email: *mrartemev.me@gmail.com*
  * My telegram: *@ meretemev*

content:
  - title: Work Experience
    layout: list
    content:
      - title: Zero10 startup
        layout: left
        caption: June 2022 - Present
        link: https://zero10.app/
        sub_title: Limassol, Cyprus
        border: weak
        description: |

          I have been involved in developing state-of-the-art algorithms for
          person **semantic segmentation**, **pose estimation**, and **keypoint detection**.
          These algorithms are designed to run at **30 FPS** on mobile devices.

          In collaboration with our team of 3D designers,
          I created a fast and efficient model for **semantic segmentation** that is able to achieve
          an impressive Intersection over Union score (IoU) of up to *0.85*,
          even on difficult classes such as hands and fingers.

          To meet our perfomance goals, I developed a novel multitask estimator
          that is able to jointly process and generate segmentation masks,
          keypoints, and UV dense pose predictions.
          This approach not only improved overall metric quality by approximately *10%*,
          but also reduced the time it took for iPhones to overheat by *4 minutes*.

          Currently, I am exploring new approaches to generative fashion design,
          including the use of Stable Diffusion for **3D point-cloud generation**
          and the development of novel GAN-based photos-to-3D model scanners.

           Examples          |  Examples           | Examples
          :-------------------------:|:-------------------------:|:-------------------------:
          ![](images/zero10/image1.jpg)   | ![](images/zero10/image2.jpg) | ![](images/zero10/image3.jpg)


      - title: Bytedance
        layout: left
        caption: October 2021 - June 2022
        link: https://www.bytedance.com/en/
        sub_title: Singapore, Singapore
        border: weak
        description: |
          As a member of the deduplication team in Singapore, I was focused on improving the accuracy of the TikTok duplicates recognition algorithm.
          In collaboration with engineering and research teams, I developed practical and innovative approaches to create **de-duplication** pipelines.
          Utilizing image features from an external CNN model and a variety of text features (such as fasttext and word2vec),
          I implemented multiple robust frame **feature-based filters** that reduced the number of duplicates that end users saw by *5%*.

          One of my major projects was designing a new architecture for **video-level embeddings** that could be used for video deduplication.
          By leveraging [Visual Transformers](https://arxiv.org/abs/2010.11929) and the [Masked AutoEncoders](https://arxiv.org/abs/2111.06377),
          I created a robust and scale-invariant **ViT** model that could produce embeddings that could be utilized in various services beyond just deduplication.

          In addition, I was responsible for setting up monitoring, building processing services with other engineers, and writing code to wrap existing ML/CV models.

      - title: PicsArt
        layout: left
        caption: May 2020 - October 2021
        link: https://picsart.com/ru
        sub_title: Yerevan, Armenia & Moscow, Russia
        border: weak
        description: |
          #### Hair Recoloring

          As the lead developer at Picsart, I successfully **managed and directed** a team of three people in the
          creation of multiple beautification solutions for the app, including a photo-realistic hair recoloring tool.
          Within a year and a half, I successfully led a small team in creating multiple beautification solutions,
          including a highly efficient and lightweight **image-to-image GAN** model for mobile environments
          The development process involved a range of tasks, including **data collection** and **annotation**,
          initial model research and training, GAN **distillation** and **quantization**.
          I also contributed to the development of our own method for GAN distillation, which is currently in submission.

          We were continually working to improve the quality and latency of the model,
          and have even created a novel approach to eliminate the need for a precise hair mask calculation,
          saving approximately *10ms* in inference time and enabling the use of hair coloring on video sequences.

          ![](images/haircolor/image1.jpg)

          ![](images/haircolor/image2.jpg)

          ![](images/haircolor/271.jpg)


          #### Hair Transfer

          In addition to my work on the hair coloring tool for Picsart,
          I also contributed to the development of an algorithm for photo-realistic hair transfer.
          As a supervisor on this project, I oversaw the implementation of key steps such as **facial keypoint detection**,
          **face alignment**, **facial segmentation**, **hair alpha mask calculation**, **statistical coloring**, and **inpainting**.



          #### Video Enhancement

          As part of PicsArt's transition to a video platform, I worked on the Video Auto Adjustment/Enhancement task.
          Our goal was to create a small but capable model that could automatically adjust brightness,
          contrast, sharpness, and other parameters in any given video to improve its overall quality.
          To achieve this, we developed a fully-convolutional model that performed regression on LAB video frames to adjust various parameters.

          [![Here should be a video link](images/preview_1.png)](https://drive.google.com/file/d/1wNRTdq3FlVdrcy9_UaYAqaJdjcS0Zcj2/view?usp=sharing)

          [![Here should be a video link](images/preview_2.png)](https://drive.google.com/file/d/10YETE0DiamgfpYHcsfetI6JbxNBMz0Z1/view?usp=sharing)

      - title: CERN & Lambda lab
        layout: left
        caption: August 2019 - August 2020
        link: https://cs.hse.ru/en/lambda/
        sub_title: Geneva, Switzerland & Moscow, Russia
        border: weak
        description: | # this will include new lines to allow paragraphs
          #### Ring Imaging Cherenkov detector

          The [Ring Imaging Cherenkov (RICH) detector](https://lhcb-public.web.cern.ch/en/detector/RICH-en.html)
          is a key component of the Large Hadron Collider beauty experiment.
          Its purpose is to identify the type of particle being passed through it by calculating the probability of a particle being a particular type.
          However, setting up a model for this purpose requires a large amount of data.

          To address this challenge, our team developed a [Cramer GAN](https://arxiv.org/abs/1705.10743),
          which is able to generate a large amount of data to simulate specific LHCb experiments.
          This allowed us to simulate data at a much faster rate (around *10,000 events per second*) compared
          to previous methods such as Monte-Carlo simulation (2-5 events per second),
          which were previously used by physicists.
          The use of the **Cramer GAN** allowed physicists to efficiently generate data for modeling particle probabilities for multiple LHCb experiments.



          #### Deep Underground Neutrino Experiment

          This project was a collaboration with FermiLab, with the goal of studying neutrino interactions with matter.
          My role in the project was to build a stable pre-processing pipeline for sparse data and to develop low-latency models for online event filtering.

          I contributed to the project by developing a **graph neural network** that denoises and sparsifies events as part of the engineering pipeline.
          To my knowledge, this solution is still being used in current DUNE experiments.
          A submission at [CHEP 2019](https://indico.cern.ch/event/773049/contributions/3474765/) provides a summary of the project.

  - title: Additional Experience
    layout: list 
    content:
      - layout: left
        title: Higher School of Economics
        link: https://www.hse.ru/en/
        caption: September 2018 - February 2022
        description: |

          I began teaching during my second year at university, initially offering private counseling sessions.
          I then became a teacher's assistant for various deep learning-related courses.

          After graduating, I created a [semester-long course called "Generative Models"](https://www.hse.ru/en/edu/courses/339563270),
          which covers a range of state-of-the-art generative models, including **GANs**, **VAEs**, and **Normalizing Flows**.

      - layout: left
        title: Yandex
        link: https://en.wikipedia.org/wiki/Yandex_Zen
        description: |
          During my student years, I interned at Yandex, where I worked on various NLP models designed to solve deduplication tasks for three months.
          While much of my work there focused on text embeddings such as **word2vec**, **fasttext**, and **doc2vec**,
          I also successfully deployed a **Siamese neural network** to production, which greatly improved the quality of deduplication.

  - title: Education
    layout: list
    content:
      - layout: left
        title: Higher School of Economics
        caption: 2015-2019
        sub_title: Moscow, Russia
        quote: >
          Even though it is called a "Higher School of Economics", the faculty I studied in is considered one of the top computer science programs
          in Russia with a focus on applied machine learning.

        description: |

          During my time at HSE, I developed key skills that have served me well throughout my career,
          such as the ability to work well in a team and meet tight deadlines.
          I enjoyed my time at university and learned about the importance of balancing work and personal life.

          I was consistently ranked among the top performers in intra-university **Kaggle** competitions
          and served as a teacher assistant during my last two years there.

          My bachelor's thesis focused on using GANs
          for the [fast simulation of particle interactions](https://arxiv.org/abs/1905.11825) for CERN's LHCb experiment

  - title: Academic Experience
    layout: list
    content:
      - layout: top-middle
        description: |
          My work with Lambda laboratory has resulted in a number of papers and talks:

          * A paper presented at the Advanced Computing and Analysis Techniques in Physics Research 2019: [Fast Data-Driven simulation of Cherenkov Detectors Using Generative Adversarial Networks](https://arxiv.org/abs/1905.11825)
          * A poster presented at NeurIPS 2019 on the same topic

          I also gave several **public talks** and **lectures** on generative models in high energy physics,
          including at the following conferences:

          * 24th International Conference on Computing in High-Energy and Nuclear Physics, 2019
          * Innovative Team-Teaching For Physics, 2019
          * Machine Learning in High Energy Physics Summer School, Oxford, 2019

          While working at PicsArt, my team and I prepared a number of papers and drafts that are covered
          by nondisclosure agreements (NDAs) and are currently in the process of being patented. These include:

          * **Knowledge Distillation of Normalizing Flows**: In this paper, we explore conventional knowledge distillation methods applied to Normalizing Flows.
          We propose a novel NF-specific KD solution that improves student flow quality by more than 30% compared to conventional methods.

          * **Deep Normalizing Flows**: As the name suggests, this paper investigates how deep we can go with Normalizing Flows while effectively increasing metrics.

          * **Very Tiny StarGan v2**: During the hair recoloring project, we developed a method for distilling an image-to-image GAN that allows
          for a stable and fast distillation process for the state-of-the-art image translation GAN, StarGAN v2.

# Footer
footer_show_references: true
#references_title: feel free to write

# Build settings
remote_theme: sproogen/resume-theme

sass:
  sass_dir: _sass
  style: compressed

plugins:
 - jekyll-seo-tag
